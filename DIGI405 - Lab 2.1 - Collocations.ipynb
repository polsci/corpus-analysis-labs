{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2732d05",
   "metadata": {},
   "source": [
    "# DIGI405 Lab 2.1: Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac533c9",
   "metadata": {},
   "source": [
    "## Lab 2 Introduction\n",
    "\n",
    "In the lab notebooks for module 2 we introduce collocation analysis, analysis of clusters and n-grams, and\n",
    "keyword analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5a863",
   "metadata": {},
   "source": [
    "### A note about the Quake Stories v2 corpus\n",
    "\n",
    "This notebook works with the Quake Stories v2 (QSv2) corpus. This data comes from\n",
    "http://www.quakestories.govt.nz/, and consists of crowd-sourced accounts of earthquake experiences\n",
    "following the 2011 Canterbury earthquakes. This corpus contains 487 self-reported stories of\n",
    "earthquake experiences from 2011 to 2019. It is licensed under Creative Commons BY-NC-SA. Please\n",
    "be aware that some stories may relate to people who were killed or injured in the earthquakes. Please\n",
    "treat the material with respect.\n",
    "\n",
    "Remember, you can read about the filename format in the README file included in the corpus zip\n",
    "file. This provides a way for you to view the original web page that each text was scraped from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b87518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conc.corpus import Corpus\n",
    "from conc.conc import Conc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = f'{os.environ.get(\"HOME\")}/data/' # path to the source data from which the corpus will be created\n",
    "save_path = f'{os.environ.get(\"HOME\")}/data/conc-test-corpora/' # path to the directory where the corpus will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a85752",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corpus = Corpus().load(f'{save_path}quake-stories-v2.corpus')\n",
    "except FileNotFoundError:\n",
    "    corpus = Corpus(name = 'Quake Stories v2', description = 'This is a corpus based on stories from the http://www.quakestories.govt.nz/ website established by ManatÅ« Taonga / Ministry for Culture and Heritage in 2011. QuakeStories was a place for the public to share stories of these and subsequent New Zealand earthquakes. The site was licensed under Creative Commons BY-NC-SA (https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en). This data-set, as a re-representation of the stories, is also released under BY-NC-SA. Please be aware that some stories may relate to people who were killed or injured in the Canterbury earthquakes. Treat the material with respect. ').build_from_files(f'{source_path}qs-v2', f'{save_path}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38939ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.summary() # overview of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = Conc(corpus) #initialize Conc reporting with the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553027c",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "\n",
    "Quantitative analysis of corpora demonstrates that collocation is a fundamental \n",
    "features of language data: words tend to occur with other words in predictable ways. \n",
    "These patterns encode meaning. In fact, in some approaches to language modelling, words \n",
    "are represented as vectors based on collocation patterns.\n",
    "\n",
    "Collocations are patterns that do not belong to individual authors, but are shared patterns \n",
    "of language use that authors are making use of to make meaning and do things with \n",
    "language. \n",
    "\n",
    "In Lab notebook 1.2 we introduced concordances as a way to view words or phrases in the\n",
    "context in which they appear in a corpus. This was our first exploration of collocation \n",
    "patterns. The patterns within concordance lines can be identified by \n",
    "sorting the concordance in different ways. Words do not always pattern in a particular \n",
    "order. While we can identify these kind of patterns by inspecting the lines in a systematic way,\n",
    "this becomes much more time-consuming (and potentially impossible) as the number of\n",
    "concordance lines increase.\n",
    "\n",
    "Collocation analysis makes use of statistical measures of collocation. Collocates can be \n",
    "ranked by different statistical measures to identify robust patterns. \n",
    "\n",
    "This lab will introduce you to concordance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c25f2",
   "metadata": {},
   "source": [
    "## Task 1: Understanding language usage by finding patterns in an example collocation table\n",
    "\n",
    "The cell below creates a collocation table for the word \"home\". The effect size measure used is \n",
    "Mutual Information (MI). Inspect the notes at the foot of the table. By default collocates are \n",
    "in a window from 5 words to the left and 5 words to the right of \"home\". \n",
    "The minimum collocation frequency is set to 5. This is appropriate for MI, which privileges very \n",
    "rare and exclusive collocates.\n",
    "\n",
    "Inspect the different columns in the table. \n",
    "* Collocate Frequency is the number of times \n",
    "'home' and the collocate token appear together. \n",
    "* Frequency is the number of times the collocate appears in the corpus (both in the context of \"home\" and in other contexts). \n",
    "* The Mutual Information values is a measure expressing the strength of the collocation.\n",
    "* Log Likelihood Ratio (LLR) is the default statistical significance measure. \n",
    "\n",
    "As with the previous Conc tables you have encountered, you can change the number of rows displayed by \n",
    "setting a `page_size` parameter. You can page through the results using `page_current`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'home'\n",
    "conc.collocates(query, effect_size_measure = 'mutual_information', context_length = 5, min_collocate_frequency = 5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6694b",
   "metadata": {},
   "source": [
    "Valid effect size measures for the Conc library are currently 'mutual_information' and 'logdice'. Create a new code cell and copy the code above. Set the effect size measure to 'logdice'. Compare the results with the first table using MI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e49f6b",
   "metadata": {},
   "source": [
    "When we look at collocates, it is common to start telling ourselves stories about the meaning of the patterns we see and the intention behind these patterns. Concordances complement collocation tables, allowing us to inspect the specific instances that two tokens are used together. The following line adds two new parameters to the concordance method introduced in previous lab notebooks. The `filter_context_str` and `filter_context_length` parameters can be set to view only those concordance lines matching our collocation results. In the example below, concordances for \"home: are filtered by lines featuring \"journey\" within 5 word tokens of the node. By inspecting concordances, we don't have to assume how two words are being used together, we can analyse the usage and make appropriate claims based on evidence from the corpus.\n",
    "\n",
    "As you work through the rest of this notebook, make a point to use concordances to inspect the patterns to test your observations and to ensure your claims accurate represent the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad98011",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'home'\n",
    "conc.concordance(query, context_length = 8, order='1R2R3R', page_current = 1, page_size = 20, filter_context_str = 'journey', filter_context_length = 5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e64ae",
   "metadata": {},
   "source": [
    "As we learned in previous lab notebooks, patterns can relate to specific tokens or to groupings of these tokens. Something to pay attention to when viewing a collocation table is whether the collocates are related in some way. Here are some questions to ask yourself as you investigate the collocates: Are there groupings of collocates related to parts of speech or meaning? Are there groupings of collocates that perform a similar function in the texts (e.g. expressing the authors attitude)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8dc3a4",
   "metadata": {},
   "source": [
    "Create a markdown cell and note your responses to the following question. \n",
    "\n",
    "* What kinds of words are considered strong collocates for each collocation measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec640a0",
   "metadata": {},
   "source": [
    "## Task 2: Changing the context\n",
    "\n",
    "Create a new table in a new code cell below using the MI measure. Experiment with different values for context_length and min_collocate_frequency. \n",
    "\n",
    "Create a markdown cell and note your observations about how these settings change the results you get."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d9022",
   "metadata": {},
   "source": [
    "You can also set the context_length independently for left and right contexts. To do this specify the context_length as a tuple `(left context length, right context length)`, for example setting context_length to `(5, 0)` will set the context length so that only collocates appearing in the 5 word tokens to the left of \"home\" are evaluated. Experiment with diferent values for the left and right context lengths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5147b8",
   "metadata": {},
   "source": [
    "Still using the query word 'home', set the context length first so that tokens immediately to the left and right of 'home' are included with `(1, 1)`. Then change it to `(1, 0)` to see the token immediately to the left, and then `(0, 1)` to see the collocates immediately to the right. Use a minimum collocate frequency of 5.\n",
    "\n",
    "Note: it might be helpful to create code cells for the three tables so you can compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591f76e",
   "metadata": {},
   "source": [
    "Create a markdown cell to note your observations:\n",
    "\n",
    "- With the settings you just tried, what kind of words are collocated with \"home\" in different positions.\n",
    "- Are there particular patterns that tend to occur on one side or other of \"home\"?\n",
    "- What do these patterns indicate about the use of \"home\" in the corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770c1ff",
   "metadata": {},
   "source": [
    "## Task 3: Comparing collocation patterns for different words\n",
    "\n",
    "In new code cells below, repeat your analysis with the word \"house\". Make sure you use concordances to complement and enhance your analysis of the collocation tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b7fb1",
   "metadata": {},
   "source": [
    "Create a new markdown cell. After you examine words collocated with âhouseâ, note your observations:\n",
    "\n",
    "- What are the differences between the use of \"home\" and \"house\" in the corpus?\n",
    "- From your examination of the use of these specific words, what are some claims you can make about features of the texts contained in the Quake Stories corpus?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93912637",
   "metadata": {},
   "source": [
    "## Task 4: Extending your analysis\n",
    "\n",
    "The frequency of a collocates appearing in a span is its own kind of raw collocation measure (i.e. how many times each collocate appears in a\n",
    "span or position). You can sort by collocate frequency by adding in the `order` parameter and setting this to `collocate_frequency`. \n",
    "\n",
    "Try this now.\n",
    "\n",
    "Note: Valid values in Conc currently are `collocate_frequency`, `frequency`, or `frequency`. If the `order` parameter is ommitted or set to `None` the results are based on the effect size measure. If you set the value to `None` it shouldn't have quotes around it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b658766",
   "metadata": {},
   "source": [
    "Focusing on \"home\" and \"house\" and the context_length `(1, 0)` can you see any differences in function words that appear to the left of \"home\" and \"house\"? Note your observations in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55603d9d",
   "metadata": {},
   "source": [
    "## Task 5: \"Time\" and filtering collocates based on evidence for robust patterns\n",
    "\n",
    "Create a code cell and create a table for token \"time\". Spend some time examining the collocates.\n",
    "\n",
    "In the results we have viewed so far, the statistical significance is reported using the Log Likelihood Ratio. We are not filtering the results to exclude collocates based on this measure. To do this you can add the `statistical_significance_cut` parameter. The value should be a desired p value (e.g. 0.05, 0.01, 0.001). This will filter out collocates that do not meet a specific statistical significance threshold. This provides a way to focus on collocation patterns with robust statistical evidence. \n",
    "\n",
    "Apply a threshold to filter collocates for the word \"time\". You can be aggressive with the threhold, e.g. 0.0001.\n",
    "\n",
    "Inspect the words collocated with \"time\". \n",
    "\n",
    "Note: In this example concordances are valuable to investigate the dispersion of collocation patterns in our corpus. In other words, we can see from the document ids in the concordances whether a collocation pattern relates to very few (or even single) texts.  In general we are looking for collocation patterns that occur across multiple texts, however it can be interesting to examine the word choices of individual authors. Remember: The claims we make about collocation patterns should be different depending on whether the patterns observed are the result of word choices by one or multiple authors.\n",
    "\n",
    "Create a markdown cell and note your observations:\n",
    "\n",
    "- What do you notice about collocates that are associated with the word âtimeâ? Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b9fee",
   "metadata": {},
   "source": [
    "## Task 6: Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d5b99",
   "metadata": {},
   "source": [
    "Reflect on the process you are using to investigate collocation patterns.\n",
    "\n",
    "* How can we improve the quality of our claims about specific collocation patterns?  \n",
    "* If we were to write about the collocation patterns we have observed what statistical information or other evidence is important?  \n",
    "* Given there are different software tools to do collocation analysis, how should we report our results in a way others can understand and reproduce?    \n",
    "\n",
    "Make notes on your answers to these questions in a markdown cell, and then discuss your findings with someone else in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c46943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
